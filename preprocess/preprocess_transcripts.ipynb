{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb58cbd-b242-452a-b433-1080efcf6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04a50fb1-a680-409a-8283-a0bbd67c673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv('full_transcript_concat.csv')\n",
    "Y = pd.DataFrame(p['happy_trans']) \n",
    "X = p.drop(['happy_trans'], axis=1)\n",
    "train,test,ytrain,ytest = train_test_split(X, Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a5944db-1266-4e8f-9d95-ac5eb85c82f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_words</th>\n",
       "      <th>seconds_trans</th>\n",
       "      <th>arousal_trans</th>\n",
       "      <th>valence_trans</th>\n",
       "      <th>angry_trans</th>\n",
       "      <th>nervous_trans</th>\n",
       "      <th>sad_trans</th>\n",
       "      <th>seconds2_trans</th>\n",
       "      <th>arousal2_trans</th>\n",
       "      <th>valence2_trans</th>\n",
       "      <th>happy2_trans</th>\n",
       "      <th>angry2_trans</th>\n",
       "      <th>nervous2_trans</th>\n",
       "      <th>sad2_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>from different cultures and all that so I'm no...</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>War isn't going to wait for people to be ready</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>now is bringing a lot of terrorism and fights ...</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>yeah that's my favorite</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>the status of refugees and I will I will provi...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>in Korea so I think Korea has already already ...</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.333</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>issues and maybe combination is first of all f...</td>\n",
       "      <td>205.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>to educate the people prior to this</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>most primary concern is the other one about th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>although the government has taken the choice t...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>340.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              new_words  seconds_trans  \\\n",
       "1359  from different cultures and all that so I'm no...          260.0   \n",
       "536      War isn't going to wait for people to be ready          145.0   \n",
       "340   now is bringing a lot of terrorism and fights ...          305.0   \n",
       "540                             yeah that's my favorite          165.0   \n",
       "735   the status of refugees and I will I will provi...           25.0   \n",
       "...                                                 ...            ...   \n",
       "1415  in Korea so I think Korea has already already ...          540.0   \n",
       "196   issues and maybe combination is first of all f...          205.0   \n",
       "65                  to educate the people prior to this          330.0   \n",
       "509   most primary concern is the other one about th...           10.0   \n",
       "67    although the government has taken the choice t...          340.0   \n",
       "\n",
       "      arousal_trans  valence_trans  angry_trans  nervous_trans  sad_trans  \\\n",
       "1359          2.667          3.333        1.667          2.000      1.333   \n",
       "536           2.000          3.000        1.000          1.333      1.000   \n",
       "340           3.000          2.667        1.333          1.333      1.000   \n",
       "540           2.000          3.333        1.000          1.333      1.000   \n",
       "735           3.667          3.000        1.667          2.000      1.000   \n",
       "...             ...            ...          ...            ...        ...   \n",
       "1415          3.667          3.000        1.667          1.667      1.333   \n",
       "196           3.333          3.667        1.667          2.000      1.000   \n",
       "65            3.333          3.000        1.000          1.333      1.000   \n",
       "509           2.667          3.333        1.000          1.333      1.000   \n",
       "67            2.667          3.333        1.000          1.333      1.000   \n",
       "\n",
       "      seconds2_trans  arousal2_trans  valence2_trans  happy2_trans  \\\n",
       "1359           260.0           2.667           2.667         1.000   \n",
       "536            145.0           2.667           2.667         1.000   \n",
       "340            305.0           2.333           2.667         2.000   \n",
       "540            165.0           2.667           2.667         1.000   \n",
       "735             25.0           2.667           3.000         1.000   \n",
       "...              ...             ...             ...           ...   \n",
       "1415           540.0           3.000           3.000         1.000   \n",
       "196            205.0           1.667           3.000         2.000   \n",
       "65             330.0           3.667           3.333         1.333   \n",
       "509             10.0           2.333           3.000         1.000   \n",
       "67             340.0           3.333           3.333         1.333   \n",
       "\n",
       "      angry2_trans  nervous2_trans  sad2_trans  \n",
       "1359         1.000           1.000       1.667  \n",
       "536          1.333           1.667       1.000  \n",
       "340          1.000           1.333       1.000  \n",
       "540          1.000           1.333       1.000  \n",
       "735          1.000           1.000       1.000  \n",
       "...            ...             ...         ...  \n",
       "1415         1.000           1.000       1.000  \n",
       "196          1.000           1.667       1.000  \n",
       "65           1.000           1.667       1.000  \n",
       "509          1.000           1.333       1.000  \n",
       "67           1.000           2.000       1.000  \n",
       "\n",
       "[1490 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af6fa21-60d4-40b2-9dcd-f91a61a39781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word_Embeddings.ipynb        preprocess_transcripts.ipynb\n",
      "preprocess_csv.ipynb         word_embeddings_1.ipynb\n",
      "preprocess_eeg.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3728e0f2-876b-4bd6-bd9f-047bb8b3369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109297c-77b0-403b-888a-f8d470a79c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_index(count, csv):\n",
    "    for i in range(count, len(brain)):\n",
    "        return i\n",
    "        break\n",
    "    for j in range(count, len(subjects)):\n",
    "        return j\n",
    "        break\n",
    "    for k in range(count,len(emotion)):\n",
    "        return k\n",
    "        break\n",
    "    if csv == 'i':\n",
    "        return i\n",
    "    if csv == 'j':\n",
    "        return j\n",
    "    if csv == 'k':\n",
    "        return k\n",
    "    \n",
    "    \n",
    "def return_col_len(csv):\n",
    "    col_len = len(csv.columns)\n",
    "    return col_len\n",
    "\n",
    "def start_time(brain, debate_start):\n",
    "    for i in range(0, len(brain)):\n",
    "        if brain.timestamp[i] >= debate_start:\n",
    "            return i\n",
    "        \n",
    "def return_column_len(emotion, count):\n",
    "    for i in range(count,len(emotion.columns)):\n",
    "        return i\n",
    "    \n",
    "def read_emotion(path_to_file, count_file):\n",
    "    for p in sorted(os.listdir(path_to_file)):\n",
    "        if '.csv' in p:\n",
    "            os.chdir(path_to_file)\n",
    "            emotion = pd.read_csv(p)\n",
    "            os.chdir('../../')\n",
    "            \n",
    "    return emotion\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d56c2f-9660-44b5-9e94-49e1580fb2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_num=1\n",
    "count = 0\n",
    "os.chdir('metadata')\n",
    "subjects = pd.read_excel('subjects os.listdir.xlsx') \n",
    "\n",
    "#subjects csv: initTime - time when data collection started\n",
    "#startTime - time when debate started \n",
    "#endTime - time when debate ended\n",
    "\n",
    "startTime = subjects['startTime']   #debate startTime\n",
    "endTime = subjects['endTime'] #debate endTime\n",
    "os.chdir('../')\n",
    "\n",
    "for p in sorted(os.listdir('emotion_annotations/self_annotations')):   #emotion annotations for each subject\n",
    "    if '.csv' in p:\n",
    "    \n",
    "        os.chdir('emotion_annotations/self_annotations')\n",
    "        emotion = pd.read_csv(p)   #read annotation csv\n",
    "        os.chdir('../../')\n",
    "        #print(emotion)\n",
    "        \n",
    "        for eeg in sorted(os.listdir('new_eeg')):    #eeg readings for each subject\n",
    "            if '.csv' in eeg:\n",
    "            \n",
    "                os.chdir('new_eeg')\n",
    "                brain = pd.read_csv(eeg)     #read eeg csv\n",
    "                \n",
    "                brain['seconds'] = ''\n",
    "                brain['arousal'] = ''\n",
    "                brain['valence'] = ''\n",
    "                brain['cheerful'] = ''\n",
    "                brain['happy'] = ''\n",
    "                brain['angry'] = ''\n",
    "                brain['nervous'] = ''\n",
    "                brain['sad'] = ''\n",
    "                brain['boredom'] = ''\n",
    "                brain['confusion'] = ''\n",
    "                brain['delight'] = ''\n",
    "                brain['concentration'] = ''\n",
    "                brain['frustration'] = ''\n",
    "                brain['surpise'] = ''\n",
    "                brain['none_1'] = ''\n",
    "                brain['confrustion'] = ''\n",
    "                brain['contempt'] = ''\n",
    "                brain['dejection'] = ''\n",
    "                brain['disgust'] = ''\n",
    "                brain['eureka'] = ''\n",
    "                brain['pride'] = ''\n",
    "                brain['sorrow'] = ''\n",
    "                brain['none_2'] = ''\n",
    "                os.chdir('../')\n",
    "                #print(brain)\n",
    "                '''\n",
    "                \n",
    "                important variables:\n",
    "                \n",
    "                timestamp in brain --> time intervals eeg recording starts\n",
    "                new_trans_time --> compounding time intervals (in seconds) \n",
    "                startTime --> time when debate starts\n",
    "                seconds in annot --> time intervals of when participant recorded their emotions\n",
    "                \n",
    "                \n",
    "                I want to\n",
    "                \n",
    "                \n",
    "                1. at timestamp >= startTime (since this is when the debate starts)\n",
    "                    a. if new_trans_time <= seconds (annot) --> concatenate emotion annotations for the corresponding seconds\n",
    "                    b. else move on to the next seconds interval (annot)\n",
    "                \n",
    "                '''\n",
    "                \n",
    "                counter = 0\n",
    "                \n",
    "                \n",
    "                debate_start = subjects.startTime[0]\n",
    "                \n",
    "                #print(debate_start)\n",
    "                \n",
    "                index = start_time(brain, debate_start) # index where debate starts\n",
    "                \n",
    "                #print(index)\n",
    "                \n",
    "                start = index\n",
    "                \n",
    "                for i in range(index, len(brain)):\n",
    "                    \n",
    "                    #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "                    #brain_time = brain.new_trans_time[i]\n",
    "            \n",
    "                    if (brain.new_trans_time[i] >= (emotion.seconds[counter] + brain.new_trans_time[start])):\n",
    "                    \n",
    "                        #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "                        \n",
    "                        counter +=1\n",
    "                        start += 1\n",
    "                        \n",
    "                    brain.iloc[i, 14:] = emotion.iloc[counter]\n",
    "                    \n",
    "                brain_new = pd.DataFrame(brain)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                os.chdir('eeg_emotion_csvs')\n",
    "                brain_new.to_csv(f'p{csv_num}a.csv', sep=',', index=False)\n",
    "                os.chdir('../')\n",
    "                count +=1\n",
    "                break\n",
    "            \n",
    "\n",
    "                \n",
    "\n",
    " \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e56870-0da3-49b6-b3a5-dcd8ea182653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2281abc-5db8-4350-8a81-0af8e50f179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_num = 32\n",
    "\n",
    "df = pd.read_csv(f'eeg_emotion_csvs/p{csv_num}.csv')\n",
    "df = df[df['seconds'].notna()]\n",
    "os.chdir('dropped_eeg_emotion')\n",
    "df.to_csv(f'p{csv_num}_eeg_emotion.csv', sep=',', index=False)\n",
    "os.chdir('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e44a8-df35-4c23-9b09-f1fc2a710efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocess eeg and emotion\n",
    "\n",
    "\n",
    "\n",
    "csv_num=32\n",
    "#start_time_index = 0\n",
    "count = 0\n",
    "# os.chdir('metadata')\n",
    "# subjects = pd.read_excel('subjects os.listdir.xlsx') \n",
    "\n",
    "#subjects csv: initTime - time when data collection started\n",
    "#startTime - time when debate started \n",
    "#endTime - time when debate ended\n",
    "\n",
    "# startTime = subjects['startTime']   #debate startTime\n",
    "# endTime = subjects['endTime'] #debate endTime\n",
    "# os.chdir('../')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "emotion = pd.read_csv(f'averaged_emotions/p{csv_num}.csv')   #read annotation csv\n",
    "\n",
    "#print(emotion)\n",
    "\n",
    "#debate_start = subjects.startTime[start_time_index]\n",
    "\n",
    "\n",
    "\n",
    "brain = pd.read_csv(f'dropped_eeg_emotion/p{csv_num}_eeg_emotion.csv')     #read eeg csv\n",
    "brain = brain.iloc[:, 0:14]\n",
    "\n",
    "\n",
    "brain['seconds'] = ''\n",
    "brain['arousal'] = ''\n",
    "brain['valence'] = ''\n",
    "brain['happy'] = ''\n",
    "brain['angry'] = ''\n",
    "brain['nervous'] = ''\n",
    "brain['sad'] = ''\n",
    "\n",
    "#print(brain)\n",
    "'''\n",
    "\n",
    "important variables:\n",
    "\n",
    "timestamp in brain --> time intervals eeg recording starts\n",
    "new_trans_time --> compounding time intervals (in seconds) \n",
    "startTime --> time when debate starts\n",
    "seconds in annot --> time intervals of when participant recorded their emotions\n",
    "\n",
    "\n",
    "I want to\n",
    "\n",
    "\n",
    "1. at timestamp >= startTime (since this is when the debate starts)\n",
    "    a. if new_trans_time <= seconds (annot) --> concatenate emotion annotations for the corresponding seconds\n",
    "    b. else move on to the next seconds interval (annot)\n",
    "\n",
    "'''\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "#print(debate_start)\n",
    "\n",
    "index = 0 # index where debate starts\n",
    "\n",
    "#print(index)\n",
    "\n",
    "start = 0\n",
    "#print(index)\n",
    "for i in range(index, len(brain)):\n",
    "\n",
    "    #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "    #brain_time = brain.new_trans_time[i]\n",
    "\n",
    "    if (brain.new_trans_time[i] >= (emotion.seconds[counter] + brain.new_trans_time[start])):\n",
    "\n",
    "        #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "\n",
    "        counter +=1\n",
    "        start += 1\n",
    "\n",
    "    brain.iloc[i, 14:] = emotion.iloc[counter]\n",
    "\n",
    "brain_new = pd.DataFrame(brain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('eeg_emotion_new')\n",
    "brain_new.to_csv(f'p{csv_num}_eeg.csv', sep=',', index=False)\n",
    "os.chdir('../')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab14006-241f-4e4a-958c-1ebf37b7440d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocess emotion and transcripts\n",
    "\n",
    "\n",
    "first = 31\n",
    "second =32\n",
    "\n",
    "emotion1 = pd.read_csv(f'averaged_emotions/p{first}.csv')   #read annotation csv\n",
    "emotion2= pd.read_csv(f'averaged_emotions/p{second}.csv')\n",
    "\n",
    "#print(emotion)\n",
    "\n",
    "\n",
    "\n",
    "transcript = pd.read_csv(f'transcripts_csv_3/best pred/p{first}.p{second}.m4a.csv')     #read eeg csv\n",
    "transcript.rename(columns = {'reult/alternative/0/word/0/tartTime' : 'startTime'}, inplace = True)\n",
    "\n",
    "transcript[f'p{first}'] = ''\n",
    "transcript['seconds'] = ''\n",
    "transcript['arousal'] = ''\n",
    "transcript['valence'] = ''\n",
    "transcript['happy'] = ''\n",
    "transcript['angry'] = ''\n",
    "transcript['nervous'] = ''\n",
    "transcript['sad'] = ''\n",
    "\n",
    "transcript[f'p{second}'] = ''\n",
    "transcript['seconds2'] = ''\n",
    "transcript['arousal2'] = ''\n",
    "transcript['valence2'] = ''\n",
    "transcript['happy2'] = ''\n",
    "transcript['angry2'] = ''\n",
    "transcript['nervous2'] = ''\n",
    "transcript['sad2'] = ''\n",
    "\n",
    "\n",
    "#print(transcript)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# fir_p = emotion1\n",
    "# fir_p = pd.DataFrame(fir_p)\n",
    "# #print(fir_p)\n",
    "\n",
    "# sec_p = emotion.iloc[:,23:]\n",
    "# sec_p = pd.DataFrame(sec_p)\n",
    "# sec_p.rename(columns = {'seconds.1' : 'seconds2'}, inplace = True)\n",
    "# #print(sec_p)\n",
    "\n",
    "\n",
    "start = 0\n",
    "\n",
    "for i in range(0, len(transcript)):\n",
    "\n",
    "    if (transcript.startTime[i] >= (emotion1.seconds[counter] + transcript.startTime[start])):\n",
    "\n",
    "        #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "\n",
    "        counter +=1\n",
    "        start += 1\n",
    "\n",
    "    transcript.iloc[i, 10:17] = emotion1.iloc[counter]\n",
    "\n",
    "\n",
    "start = 0\n",
    "counter = 0\n",
    "for j in range(0, len(transcript)):\n",
    "\n",
    "    if ((transcript.startTime[j] >= (emotion2.seconds[counter] + transcript.startTime[start]))):\n",
    "\n",
    "        #print(brain.new_trans_time[i], (emotion.seconds[counter] + brain.new_trans_time[start]))\n",
    "\n",
    "        counter +=1\n",
    "        start += 1\n",
    "\n",
    "    transcript.iloc[j, 18:25] = emotion2.iloc[counter]\n",
    "\n",
    "\n",
    "transcript_new = pd.DataFrame(transcript)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('newest_transcript')\n",
    "transcript_new.to_csv(f'p{first}.p{second}.csv', sep=',', index=False)\n",
    "os.chdir('../')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25c707-4828-48fa-b27b-2db554592ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = 31\n",
    "# second = 32\n",
    "num = 32\n",
    "\n",
    "# df = pd.read_csv(f'transcript_emotion_6class/p{first}.p{second}.csv')\n",
    "df2 = pd.read_csv(f'eeg_emotion_6class/p{num}_eeg.csv')\n",
    "\n",
    "# df0 = df.iloc[:, 0:13]\n",
    "# df1 = df.iloc[:, 17:21]\n",
    "# # print(df)\n",
    "# # print(df1)\n",
    "# df = pd.concat([df0, df1], axis=1)\n",
    "\n",
    "# os.chdir('binary_class_transcript')\n",
    "# df.to_csv(f'p{first}.p{second}.transcript.csv', sep=',', index=False)\n",
    "# os.chdir('../')\n",
    "\n",
    "df2 = df.iloc[:, 0:17]\n",
    "os.chdir('binary_class_eeg')\n",
    "df.to_csv(f'p{num}.eeg.csv', sep=',', index = False)\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e954642-cfaf-460d-b744-42a5b8e328aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a92dc-961e-47fa-ba6d-91086e1c7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874a6ff-88f6-4186-82f4-e5d83309b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('emotion_annotations/partner_annotations/P1.partner.csv')\n",
    "df2 = pd.read_csv('emotion_annotations/self_annotations/P1.self.csv')\n",
    "df3 = pd.read_csv('emotion_annotations/aggregated_external_annotations/P1.external.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48633d06-0341-4841-b734-88bd6baa0f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df1), len(df2), len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b5011-408a-41d5-9389-26d756e6bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1.iloc[:, 0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201eef15-1205-4c8d-9466-0134b982c13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04003eba-a215-4ebf-a2a6-bd0c756e336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_num = 32\n",
    "df1 = pd.read_csv(f'emotion_annotations/partner_annotations/P{csv_num}.partner.csv')\n",
    "df2 = pd.read_csv(f'emotion_annotations/self_annotations/P{csv_num}.self.csv')\n",
    "df3 = pd.read_csv(f'emotion_annotations/aggregated_external_annotations/P{csv_num}.external.csv')\n",
    "\n",
    "\n",
    "#keep most important emotions\n",
    "df1= df1.iloc[:, 0:8]\n",
    "df2 = df2.iloc[:,0:8]\n",
    "df3 = df3.iloc[:, 0:8]\n",
    "\n",
    "#drop cheerful\n",
    "df1 = df1.drop(labels = 'cheerful', axis = 1)\n",
    "df2 = df2.drop(labels = 'cheerful', axis = 1)\n",
    "df3 = df3.drop(labels = 'cheerful', axis = 1)\n",
    "\n",
    "\n",
    "new_df = pd.concat([df1, df2, df3]).groupby(level=0).mean().round(3)\n",
    "os.chdir('averaged_emotions')\n",
    "new_df.to_csv(f'p{csv_num}.csv', sep = ',', index = False)\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748b6d2-9da7-4aa5-9d8e-132fb6111e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032bc12-d3e0-4b57-882c-72365566c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25b10b-5359-40e9-afa7-dc0571982958",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1f9e8-b9ec-46fd-936c-dc51a0cd87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('new_eeg/BrainWave_p1.csv')\n",
    "df2 = pd.read_csv('emotion_annotations/self_annotations/P1.self.csv')\n",
    "df3 = prd.read_csv('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9408d-7ae3-4c5d-b24a-3140904f0b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f90cfd-d128-401b-bbb8-d91dcef40c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transcript_emotion_6class/p1.p2.csv')\n",
    "df.rename(columns = {'results/alternatives/0/transcript' : 'full_transcript'}, inplace = True) \n",
    "df.rename(columns = {'results/alternatives/0/words/0/word' : 'word'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3a3bd-1538-44f5-903d-78dfd45bd9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.word[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e08c0-fea3-4c88-abc8-d886360c352a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list0 = []\n",
    "word_list1 = []\n",
    "\n",
    "# for j in range(0, len(df)):\n",
    "for i in range(0, len(df)-1):\n",
    "    if (df.seconds[i] == df.seconds[i+1]):\n",
    "        #print(df.iloc[:i+2, 5])\n",
    "        #print(df.word[i+1])\n",
    "        word_list = df.word[i]\n",
    "        #print(word_list)\n",
    "        word_list0.append(word_list)\n",
    "        \n",
    "        \n",
    "        #print(word_list0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        word_list0.append(df.word[i])\n",
    "        word_list1.append(word_list0)\n",
    "\n",
    "        word_list0=[]\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008e872-ee5d-441d-9d27-58adb7e407a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_list1[0] = ' '.join(word_list1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc572248-c133-4ecc-9c17-9cd62a69dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc3b76-60f7-4870-9bbe-7c45d70c1e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in word_list1:\n",
    "    df['"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296ce95-ac62-4b6d-b781-01a67f0288bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70529639-6da3-4664-b482-571b232bbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num = 32\n",
    "\n",
    "eeg = pd.read_csv(f'eeg_emotion_6class/p{p_num}_eeg.csv')\n",
    "\n",
    "\n",
    "\n",
    "word_list0 = []\n",
    "word_list1 = []\n",
    "df = pd.DataFrame()\n",
    "df1 = pd.DataFrame()\n",
    "# for j in range(0, len(df)):\n",
    "for i in range(0, len(eeg)-1):\n",
    "    if (eeg.seconds[i] == eeg.seconds[i+1]):\n",
    "        \n",
    "        \n",
    "        word_list = eeg.iloc[i, 1:9] \n",
    "        \n",
    "\n",
    "        df = df.append(word_list)\n",
    "        #print(df)\n",
    "        #break\n",
    "        #print(word_list0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        df = df.append(eeg.iloc[i, 1:9])\n",
    "        df = df.mean(axis=0).round(3)\n",
    "        df = df.to_frame().T\n",
    "        df1 = df1.append(df)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        #df1 = df1.append(df)\n",
    "        \n",
    "        \n",
    "        #df = df.iloc[:].mean(axis=0)\n",
    "        \n",
    "        #print(df)\n",
    "        \n",
    "        #word_list1.append(word_list0)\n",
    "        \n",
    "        \n",
    "\n",
    "        #word_list0=[]\n",
    "\n",
    "df1.to_csv(f'p{p_num}.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2969d0da-fd7c-4458-9c0e-578ad11a205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(f'p{p_num}.csv', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f414932-6533-4953-b4d5-1101801850de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = pd.DataFrame(word_list0, columns = [['delta', 'lowAlpha', 'highAlpha', 'lowBeta', 'highBeta', 'lowGamma', 'middleGamma', 'theta']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3f6f5-9313-4f8b-a499-3bb9cf9621e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('eeg_emotion_6class/p1_eeg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75686d5-465b-4856-beef-7d1e29ea54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ed29c-c5b4-481c-ae23-5b7d9a906200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e116ca2-c978-43ef-8177-327deb7ddd25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff.iloc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2083396-08c3-439d-830c-172d9aa9a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_num = 32\n",
    "\n",
    "eeg = pd.read_csv(f'eeg_emotion_6class_ave/p{p_num}.csv')\n",
    "eeg['seconds'] = ''\n",
    "eeg['arousal'] = ''\n",
    "eeg['valence'] = ''\n",
    "eeg['happy'] = ''\n",
    "eeg['angry'] = ''\n",
    "eeg['nervous'] = ''\n",
    "eeg['sad'] = ''\n",
    "emotion = pd.read_csv(f'not_in_use/averaged_emotions/p{p_num}.csv')\n",
    "\n",
    "for i in range(0, len(eeg)):\n",
    "    eeg.iloc[i, 8:] = emotion.iloc[i]\n",
    "    \n",
    "os.chdir('eeg_emotion_6class_ave_new')\n",
    "eeg.to_csv(f'p{p_num}.csv', sep=',', index = False)\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff6b79dc-6a3d-4618-853f-6a529f1fbe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>lowAlpha</th>\n",
       "      <th>highAlpha</th>\n",
       "      <th>lowBeta</th>\n",
       "      <th>highBeta</th>\n",
       "      <th>lowGamma</th>\n",
       "      <th>middleGamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>seconds</th>\n",
       "      <th>arousal</th>\n",
       "      <th>valence</th>\n",
       "      <th>happy</th>\n",
       "      <th>angry</th>\n",
       "      <th>nervous</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45742.500</td>\n",
       "      <td>67405.500</td>\n",
       "      <td>50576.167</td>\n",
       "      <td>67178.500</td>\n",
       "      <td>7241.000</td>\n",
       "      <td>14181.833</td>\n",
       "      <td>726455.333</td>\n",
       "      <td>373683.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73880.000</td>\n",
       "      <td>74362.667</td>\n",
       "      <td>41225.000</td>\n",
       "      <td>63429.833</td>\n",
       "      <td>4687.000</td>\n",
       "      <td>8935.833</td>\n",
       "      <td>847929.833</td>\n",
       "      <td>155085.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46340.833</td>\n",
       "      <td>47721.833</td>\n",
       "      <td>32669.500</td>\n",
       "      <td>49828.667</td>\n",
       "      <td>4458.167</td>\n",
       "      <td>10709.500</td>\n",
       "      <td>1030197.000</td>\n",
       "      <td>193099.333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110589.333</td>\n",
       "      <td>72830.000</td>\n",
       "      <td>55549.000</td>\n",
       "      <td>77984.667</td>\n",
       "      <td>7002.833</td>\n",
       "      <td>15881.667</td>\n",
       "      <td>902531.667</td>\n",
       "      <td>433750.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79391.667</td>\n",
       "      <td>126444.500</td>\n",
       "      <td>42396.500</td>\n",
       "      <td>95028.000</td>\n",
       "      <td>7539.667</td>\n",
       "      <td>18323.667</td>\n",
       "      <td>676502.833</td>\n",
       "      <td>393413.333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>141146.500</td>\n",
       "      <td>192322.833</td>\n",
       "      <td>131572.833</td>\n",
       "      <td>183990.167</td>\n",
       "      <td>11406.333</td>\n",
       "      <td>35694.000</td>\n",
       "      <td>1206838.667</td>\n",
       "      <td>382460.167</td>\n",
       "      <td>690.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>135907.667</td>\n",
       "      <td>278290.000</td>\n",
       "      <td>218933.333</td>\n",
       "      <td>129140.333</td>\n",
       "      <td>10901.833</td>\n",
       "      <td>26564.333</td>\n",
       "      <td>769591.000</td>\n",
       "      <td>528911.833</td>\n",
       "      <td>695.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>49035.667</td>\n",
       "      <td>81548.000</td>\n",
       "      <td>70287.667</td>\n",
       "      <td>196562.833</td>\n",
       "      <td>4979.167</td>\n",
       "      <td>15802.667</td>\n",
       "      <td>456812.167</td>\n",
       "      <td>315556.500</td>\n",
       "      <td>700.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>170034.667</td>\n",
       "      <td>327518.333</td>\n",
       "      <td>304761.167</td>\n",
       "      <td>142458.500</td>\n",
       "      <td>11367.833</td>\n",
       "      <td>19771.333</td>\n",
       "      <td>1935523.667</td>\n",
       "      <td>866855.500</td>\n",
       "      <td>705.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>88484.167</td>\n",
       "      <td>73327.833</td>\n",
       "      <td>83027.333</td>\n",
       "      <td>133606.500</td>\n",
       "      <td>8751.833</td>\n",
       "      <td>12944.833</td>\n",
       "      <td>665895.667</td>\n",
       "      <td>560779.500</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          delta    lowAlpha   highAlpha     lowBeta   highBeta   lowGamma  \\\n",
       "0     45742.500   67405.500   50576.167   67178.500   7241.000  14181.833   \n",
       "1     73880.000   74362.667   41225.000   63429.833   4687.000   8935.833   \n",
       "2     46340.833   47721.833   32669.500   49828.667   4458.167  10709.500   \n",
       "3    110589.333   72830.000   55549.000   77984.667   7002.833  15881.667   \n",
       "4     79391.667  126444.500   42396.500   95028.000   7539.667  18323.667   \n",
       "..          ...         ...         ...         ...        ...        ...   \n",
       "137  141146.500  192322.833  131572.833  183990.167  11406.333  35694.000   \n",
       "138  135907.667  278290.000  218933.333  129140.333  10901.833  26564.333   \n",
       "139   49035.667   81548.000   70287.667  196562.833   4979.167  15802.667   \n",
       "140  170034.667  327518.333  304761.167  142458.500  11367.833  19771.333   \n",
       "141   88484.167   73327.833   83027.333  133606.500   8751.833  12944.833   \n",
       "\n",
       "     middleGamma       theta seconds arousal valence  happy angry nervous  sad  \n",
       "0     726455.333  373683.833     5.0   1.333   2.667  1.667   1.0   1.333  1.0  \n",
       "1     847929.833  155085.333    10.0   1.667   2.667  1.667   1.0   1.333  1.0  \n",
       "2    1030197.000  193099.333    15.0     2.0   2.667  1.333   1.0   1.333  1.0  \n",
       "3     902531.667  433750.333    20.0     2.0     3.0  1.333   1.0   1.333  1.0  \n",
       "4     676502.833  393413.333    25.0     2.0     3.0  1.333   1.0   1.333  1.0  \n",
       "..           ...         ...     ...     ...     ...    ...   ...     ...  ...  \n",
       "137  1206838.667  382460.167   690.0     3.0     3.0  1.333   1.0   1.667  1.0  \n",
       "138   769591.000  528911.833   695.0   2.667   3.333  1.333   1.0   1.333  1.0  \n",
       "139   456812.167  315556.500   700.0   2.667     3.0  1.333   1.0   1.333  1.0  \n",
       "140  1935523.667  866855.500   705.0   2.667     3.0  1.333   1.0   1.333  1.0  \n",
       "141   665895.667  560779.500   710.0   2.667     3.0  1.333   1.0   1.333  1.0  \n",
       "\n",
       "[142 rows x 15 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1af035-9383-4ef1-9211-dced34567041",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/70/s03t_xm53wq9db1vxd6l5d8c0000gn/T/ipykernel_80523/1693030495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtranscript_eeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtranscript_eeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'p{p_num}.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p_num' is not defined"
     ]
    }
   ],
   "source": [
    "fir_p = 1\n",
    "\n",
    "sec_p = 2\n",
    "\n",
    "p = 1\n",
    "\n",
    "transcript = pd.read_csv(f'transcript_emotion_6class/p{fir_p}.p{sec_p}a.csv')\n",
    "\n",
    "new_df = transcript.iloc[:, 27:]\n",
    "new_df = new_df.dropna(subset=['new_words'])\n",
    "\n",
    "eeg = pd.read_csv(f'eeg_emotion_6class_ave/p{p}.csv')\n",
    "\n",
    "transcript_eeg = pd.concat([new_df, eeg], axis = 1)\n",
    "transcript_eeg.to_csv(f'p{fir_p}.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e89d2cc-e590-4ed8-97ec-3b2d7607cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_words</th>\n",
       "      <th>p1_trans</th>\n",
       "      <th>seconds_trans</th>\n",
       "      <th>arousal_trans</th>\n",
       "      <th>valence_trans</th>\n",
       "      <th>happy_trans</th>\n",
       "      <th>angry_trans</th>\n",
       "      <th>nervous_trans</th>\n",
       "      <th>sad_trans</th>\n",
       "      <th>p2_trans</th>\n",
       "      <th>...</th>\n",
       "      <th>lowGamma</th>\n",
       "      <th>middleGamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>seconds</th>\n",
       "      <th>arousal</th>\n",
       "      <th>valence</th>\n",
       "      <th>happy</th>\n",
       "      <th>angry</th>\n",
       "      <th>nervous</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all right first one the state for this accepti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14181.833</td>\n",
       "      <td>726455.333</td>\n",
       "      <td>373683.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrived in this especially in many Arab Jesus ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8935.833</td>\n",
       "      <td>847929.833</td>\n",
       "      <td>155085.333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeju Allah first of all I want to mention that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10709.500</td>\n",
       "      <td>1030197.000</td>\n",
       "      <td>193099.333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.667</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movement in South Korea against against this y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15881.667</td>\n",
       "      <td>902531.667</td>\n",
       "      <td>433750.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much standard phobic activity because</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18323.667</td>\n",
       "      <td>676502.833</td>\n",
       "      <td>393413.333</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>are not on that own citizens compared to the f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>fully take care of the refugees in large amoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>765.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>accept them in Korea I want to be able to full...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>770.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>should also accept the consequences that are K...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>limited okay experience is over</td>\n",
       "      <td>NaN</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_words  p1_trans  \\\n",
       "0    all right first one the state for this accepti...       NaN   \n",
       "1    arrived in this especially in many Arab Jesus ...       NaN   \n",
       "2    Jeju Allah first of all I want to mention that...       NaN   \n",
       "3    movement in South Korea against against this y...       NaN   \n",
       "4         pretty much standard phobic activity because       NaN   \n",
       "..                                                 ...       ...   \n",
       "151  are not on that own citizens compared to the f...       NaN   \n",
       "152  fully take care of the refugees in large amoun...       NaN   \n",
       "153  accept them in Korea I want to be able to full...       NaN   \n",
       "154  should also accept the consequences that are K...       NaN   \n",
       "155                    limited okay experience is over       NaN   \n",
       "\n",
       "     seconds_trans  arousal_trans  valence_trans  happy_trans  angry_trans  \\\n",
       "0              5.0          1.333          2.667        1.667          1.0   \n",
       "1             10.0          1.667          2.667        1.667          1.0   \n",
       "2             15.0          2.000          2.667        1.333          1.0   \n",
       "3             20.0          2.000          3.000        1.333          1.0   \n",
       "4             25.0          2.000          3.000        1.333          1.0   \n",
       "..             ...            ...            ...          ...          ...   \n",
       "151          760.0          2.333          3.000        1.333          1.0   \n",
       "152          765.0          2.000          3.000        1.333          1.0   \n",
       "153          770.0          2.667          3.000        1.333          1.0   \n",
       "154          775.0          2.667          3.000        1.333          1.0   \n",
       "155          780.0          2.667          3.000        1.333          1.0   \n",
       "\n",
       "     nervous_trans  sad_trans  p2_trans  ...   lowGamma  middleGamma  \\\n",
       "0            1.333        1.0       NaN  ...  14181.833   726455.333   \n",
       "1            1.333        1.0       NaN  ...   8935.833   847929.833   \n",
       "2            1.333        1.0       NaN  ...  10709.500  1030197.000   \n",
       "3            1.333        1.0       NaN  ...  15881.667   902531.667   \n",
       "4            1.333        1.0       NaN  ...  18323.667   676502.833   \n",
       "..             ...        ...       ...  ...        ...          ...   \n",
       "151          1.333        1.0       NaN  ...        NaN          NaN   \n",
       "152          1.333        1.0       NaN  ...        NaN          NaN   \n",
       "153          1.333        1.0       NaN  ...        NaN          NaN   \n",
       "154          1.000        1.0       NaN  ...        NaN          NaN   \n",
       "155          1.000        1.0       NaN  ...        NaN          NaN   \n",
       "\n",
       "          theta  seconds  arousal  valence  happy  angry  nervous  sad  \n",
       "0    373683.833      5.0    1.333    2.667  1.667    1.0    1.333  1.0  \n",
       "1    155085.333     10.0    1.667    2.667  1.667    1.0    1.333  1.0  \n",
       "2    193099.333     15.0    2.000    2.667  1.333    1.0    1.333  1.0  \n",
       "3    433750.333     20.0    2.000    3.000  1.333    1.0    1.333  1.0  \n",
       "4    393413.333     25.0    2.000    3.000  1.333    1.0    1.333  1.0  \n",
       "..          ...      ...      ...      ...    ...    ...      ...  ...  \n",
       "151         NaN      NaN      NaN      NaN    NaN    NaN      NaN  NaN  \n",
       "152         NaN      NaN      NaN      NaN    NaN    NaN      NaN  NaN  \n",
       "153         NaN      NaN      NaN      NaN    NaN    NaN      NaN  NaN  \n",
       "154         NaN      NaN      NaN      NaN    NaN    NaN      NaN  NaN  \n",
       "155         NaN      NaN      NaN      NaN    NaN    NaN      NaN  NaN  \n",
       "\n",
       "[156 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f309064-f4a3-4251-afcf-7224ec719ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
